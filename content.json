[{"title":"李宁公益","date":"2017-08-06T07:19:22.000Z","path":"2017/08/06/李宁公益/","text":"精彩文章 爱是我们的底色 李宁荣获“中国妇女儿童慈善奖”","tags":[{"name":"李宁招聘","slug":"李宁招聘","permalink":"http://yoursite.com/tags/李宁招聘/"}]},{"title":"谈谈我自己（二）","date":"2017-07-02T00:38:30.000Z","path":"2017/07/02/谈谈我自己（二）/","text":"心有猛虎，须细嗅蔷薇 转眼，已经毕业了一个星期了，开始和社会进行近距离亲密接触了。距离上一次总结，时间划过了六个月，一年能够有多少个六个月，一生能有多少个六个月，时光总是最无情的，无论你珍惜不珍惜，它总是走着；时光总是最有情的，无论你愿意不愿意，它总是记录着。 这半年，我做了什么毕业，完成了毕设，成绩A+，第一次很认真完成的项目。毕业，给人生的前22年划上一个句号旅游，和欣欣毕业旅游，一路走过：杭州、苏州、上海、南京，很多难忘的风景，铭心的风光工作，找实习工作，来到了来也，一个期待中的公司与期待中的工作，学习、交友，不亦乐乎 下半年，打算做什么珍惜，珍惜研一的读书时光，学习心中想学的，学好必须要学的锻炼，加强游泳、滑板技能，或许，我也是个滑板达人哦交友，天南海北，学会生活责任，学会承担责任，虽不为君子，仍需一诺千金 对自己说的话Dikea，不要局限自己，现在的努力，是为了以后的不留遗憾，只要你想，就努力去做。此外，期待自己少一点浮躁，多一些专注。 附：四年前的只言片语 勇者，就是一个奇迹 勇者，是微笑着面对不幸的人摔倒后毅然跃起含笑前行执着于远方的梦想心中那盏明灯永不灭 也许，远方是去不了的地方但，那又怎样先让心灵去抵达梦想的彼岸然后，奋斗、拼搏、永不言弃让身再抵达 也许，我们的存在早已是一个感动鸟语花香的奇迹我已是永不言弃的勇者奋斗，拼搏为了爱我的人为了我爱的人 勇者，就是一个奇迹 2013年2月6日","tags":[{"name":"我思","slug":"我思","permalink":"http://yoursite.com/tags/我思/"}]},{"title":"The Non-Designer's Design Book | Reading Notes","date":"2017-07-01T11:12:05.000Z","path":"2017/07/01/The-Non-Designer-s-Design-Book-Reading-Notes/","text":"","tags":[]},{"title":"Neural Networks and Deep Learning | 读书笔记","date":"2017-07-01T08:27:52.000Z","path":"2017/07/01/Neural-Networks-and-Deep-Learning-读书笔记/","text":"前言：自己对自然语言处理方向比较感兴趣，眼下NLP与深度学习神经网络结合的比较紧密。于是也开始进行神经网络相关知识的学习，近来闲暇的时候，会去阅读一本书：Neural Networks and Deep Learning。这本书是写给深度学习小白的入门书，读者只要对微积分有些许的了解，外加一些简单的逻辑推理，就可以不费力的阅读。 Preface What this book is about: 叙述了这本书的写作目的。 On the exercises and problems: 说明了书中的exercise和problem板块的作用。 Chapter 1 | Using neural nets to recognize handwritten digitsChapter 2 | How the backpropagation algorithm works阅读完这一章，记在脑海中的，是BP1~4公式。作者通过多种方式，去解释公式的缘由以及合理性。 Chapter 3 | Improving the way neural networks learn之前章节介绍的是最简单的神经网络，这儿存在很多对其进行优化的地方。这一章将会介绍几种常见的技巧，去提高神经网络学习的质量。 3.1 交叉熵费用函数Chapter 4 | A visual proof that neural nets can compute any functionChapter 5 | Why are deep neural networks hard to train?Chapter 6 | Deep learning","tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"Useful Python Code | 有用的python代码片段","date":"2017-07-01T05:43:33.000Z","path":"2017/07/01/Useful-Python-Code/","text":"","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Machine Learning in Action | 读书笔记","date":"2017-06-10T08:11:39.000Z","path":"2017/06/10/Machine-Learning-in-Action-Reading-Notes/","text":"前言：最近在阅读《机器学习实战》这本书。为了追求速度，看的是中文的译本。这本书对于基础的机器学习算法讲解的很细致，易于理解。为了方便记忆，特提炼看到的心得，作笔记如下。此笔记只为笔者所作，读者若是觉得逻辑混乱，大可不看。 第一章 机器学习基础本章概要讲解了机器学习的概念和关键术语。说明了使用python作为机器学习入门语言的优势。介绍了一些python中常见的机器学习函数库。 第二章 K近邻算法本章概要讲解了K近邻算法的原理，将其应用到改进约会网站的配对效果以及手写数字的分类识别中。 算法理解K近邻算法：存在一个训练数据集合，其中每个数据都有着标签。输入没有标签的测试数据之后，将测试数据的每个特征与训练数据对应的特征进行比较，然后提取训练数据集中最近邻的的前k个分类数据（一般k不大于20）。最后，选择这k个相似数据中出现次数最多的分类，作为新数据的分类。 第三章 决策树本章概要介绍了决策树的主要思想，实现了决策树的代码，并且可视化出了决策树。这里主要介绍的是使用ID3算法生成的决策树，并且使用决策树预测隐形眼镜类型。 算法理解决策树通过在每个节点的推断分解，逐步缩小数据的所属范围，从而最终得到数据较为准确的分类。在每个节点对数据进行分类的时候，都需要寻找数据最好的分类特征。那么，什么特征称得上最好呢？如果这个特征包含的信息越多，根据这个特征的分类肯定是比较合理的。因为包含的信息越多，就越能将大部分数据分成不同的类别。相反，如果包含的信息很少，只能作用于很少的数据，使得分类的效果不好。这里信息的度量方式，使用著名的信息熵（香农大神提出的）来表示。 注意：决策树的训练需要耗费大量时间，但使用构建好的决策树去分类问题却很快。为了节省计算时间，可以使用python模块pickle序列化对象，序列化对象可以保存到磁盘，也就是模型可以保存到磁盘，每次需要使用的时候再读取出来。 第四章 基于概率论的分类方法：朴素贝叶斯本章概要学习使用概率分布进行分类，学习朴素贝叶斯分类器，并且使用其来分析不同地区的态度。 算法理解首先，如果不能够从原理理解贝叶斯公式，也可以简单的通过推导得到该公式。我们可以通过该公式，从已有的（训练数据集）概率来推算未知数据所属集合，继而得到分类结果。这一章不仅仅讲了贝叶斯，也描述了一些其他的概念，例如词向量、RSS等等，以及一些编程的技巧，着实学习到了不少东西。 第五章 Logistic回归本章概要这一章是最优化算法的入门，介绍了Logistics回归算法以及sigmoid函数，理论和实践结合，让我第一次明白这个东西有啥用了。我们可以利用sigmoid函数来进行分类，该函数的输入为：Z = W0X0 + W1X1 + … + WnXn,其中系数X0, X1, …, Xn的确定，可以通过最优化算法确定较优的回归系数。本章介绍的最优化算法：梯度上升法，梯度下降法（前者可以用来求解最大值，后者可以用来求解最小值），另外还有优化的随机梯度上升法。 算法理解有时候，不要纠结于公式，而是要从逻辑、思维的角度去看看该怎么做。因为有时候看公式的推导，百思不得其解，如果从逻辑（这里的逻辑有点类似人的直觉）的角度来看，反而很容易得出正确的结论。两者结合，事半功倍。","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"谈谈我自己（一）","date":"2017-01-02T12:04:39.000Z","path":"2017/01/02/谈谈我自己/","text":"心有猛虎，须细嗅蔷薇 新年的一年开始了，转眼，人生已经度过了22个春夏秋冬。在这旅途中，我需要寻找到自己。顺便总结一下刚刚结束的2016下半年，我做了什么。首先是顺利结束了所有的课程，拿到了驾照，学会了游泳。同时，通过自身的努力，挣了一小笔钱，买了自己梦寐以求的新款苹果电脑。和雅欣一起增进感情，也给了初到北京的姐姐一些力所能及的帮助。这是生活上的，那学习呢？成功保研中科院，开始了坐班实习生活，认识了很不错的老师、学长，大家都很nice，但似乎心中对于新的环境还是有着潜潜的惴惴不安，需要尽快适应环境，找到自己的style。 目前最大的问题 new year，我要挑战自己，直面身上的那些臭习惯、坏毛病，移走面前阻碍前行的几座大山。 向畏惧说不 因为有所畏惧，在挑战面前，总会倾向于半途放弃，没有坚持的勇气；因为有所畏惧，在机遇面前，总会给自己一个恰如其分的借口，错失良机； 2017，我要无所畏惧，慢慢来，会更快。 向拖延说不 和大多数人一样，我是一个拖延症早期患者，还可以抢救一下。坚决执行番茄工作法，细化每天的小目标。 向空白说不 生活，还有远方。想要未来的日子过的安逸一点，需要眼下的未雨绸缪。最惨的莫过于，时钟滴答之后，留下的只是空白。心中时刻有着准备，未来就不会那么无奈。 2017，我在这里，和你在一起","tags":[{"name":"我思","slug":"我思","permalink":"http://yoursite.com/tags/我思/"}]}]